---
name: run-and-fix-tests
description: Build the project, run tests and systematically fix any failures. Activate when user says phrases such as "run tests", "test", "build and test" or "fix tests".
---

## 0. Resolve Plugin Root

â†’ Resolve plugin root environment (check local project first, then user home):
```bash
RESOLVER=""
if [ -x "./.claude/resolve_plugin_root.sh" ]; then
  RESOLVER="./.claude/resolve_plugin_root.sh"
elif [ -x "$HOME/.claude/resolve_plugin_root.sh" ]; then
  RESOLVER="$HOME/.claude/resolve_plugin_root.sh"
else
  echo "Error: resolve_plugin_root.sh not found in ./.claude/ or $HOME/.claude/" >&2
  exit 1
fi
CLAUDE_PLUGIN_ROOT="$($RESOLVER "dev-workflow@noahlz.github.io")" || { echo "Error: Failed to resolve plugin root" >&2; exit 1; }
export CLAUDE_PLUGIN_ROOT
```

âœ“ Plugin root resolved â†’ Proceed to step 1 (Detect Build Configuration)

## 1. Detect Build Configuration

â†’ Check if `.claude/settings.plugins.run-and-fix-tests.json` exists  
âœ“ Config exists â†’ Proceed to step 2  
âœ— Config missing â†’ Run detection and auto-config:  

â†’ Source: `${CLAUDE_PLUGIN_ROOT}/skills/run-and-fix-tests/scripts/detect-and-resolve.sh`
  - Scans project for build tool config files (package.json, pom.xml, build.gradle, etc.)
  - Detects which tools are present
  - Automatically selects and applies appropriate default configuration

â†’ Auto-selection rules:
  - Exactly 1 tool detected â†’ Use `defaults/{tool}.json`
  - Multiple tools in different locations â†’ Generate polyglot config (ðŸ”§ shown to user)
  - Multiple tools in same location â†’ Generate polyglot config
  - No matching default exists â†’ Use `TEMPLATE.json` placeholder template (user must customize)
  - 0 tools detected â†’ Error: no build tools detected

âœ“ Config created successfully â†’ Proceed to step 2  
âœ— No tools detected â†’ Error, user must create `.claude/settings.plugins.run-and-fix-tests.json` manually  
âœ— Using placeholder config â†’ User must edit `.claude/settings.plugins.run-and-fix-tests.json` before step 2  

## 2. Load Configuration

â†’ Execute load-config script to output configuration as eval-able statements:
```bash
eval "$(${CLAUDE_PLUGIN_ROOT}/skills/run-and-fix-tests/scripts/load-config.sh "${CLAUDE_PLUGIN_ROOT}")"
```
âœ— Script fails â†’ Display error and stop  
âœ“ Script succeeds â†’ Environment variables set:
  - BUILD_CMD, BUILD_LOG, BUILD_ERROR_PATTERN, BUILD_WORKING_DIR
  - TEST_CMD, TEST_LOG, TEST_ERROR_PATTERN
  - TEST_SINGLE_CMD, TEST_SINGLE_LOG, TEST_SINGLE_ERROR_PATTERN
  - LOG_DIR (tool-specific, e.g., dist/, build/, target/)
  - BUILD_MULTI (true if multi-build, false if single)

â†’ Check command argument: `TEST_FILE="$1"`  
â†’ Determine mode:
  - `$TEST_FILE` not empty â†’ Single test mode
  - `$TEST_FILE` empty â†’ All tests mode

â†’ Store initial working directory: `INITIAL_PWD=$(pwd)`

## 3. Build Project

â†’ Create log directory: `mkdir -p "$LOG_DIR"`
â†’ Check build type: `$BUILD_MULTI`

**Single Build:**  
â†’ Change to build working directory: `cd "$BUILD_WORKING_DIR"`  
â†’ Execute build command silently to log file: `$BUILD_CMD > "$BUILD_LOG" 2>&1`  
âœ“ Exit 0 â†’ Return to INITIAL_PWD, proceed to step 4 (Run Tests)  
âœ— Exit non-zero â†’ Return to INITIAL_PWD, proceed to step 3a (Extract Build Errors)  

**Multi-Build:**  
â†’ For each build in detected tools:  
  â†’ Change to build working directory  
  â†’ Execute build command silently to log file: `$BUILD_CMD > "$BUILD_LOG" 2>&1`  
  â†’ On success: continue to next build  
  â†’ On failure: return to INITIAL_PWD, proceed to step 3a (Extract Build Errors)  

âœ“ All builds succeed â†’ Return to INITIAL_PWD, proceed to step 4 (Run Tests)

## 3a. Extract Build Errors

â†’ Try to get language diagnostics from editor using available IDE MCP or LSP tools  
âœ“ MCP or LSP tool available â†’ Extract errors with precise locations  
âœ— Not available â†’ Parse build log at `$BUILD_LOG` using `$BUILD_ERROR_PATTERN` regex  

â†’ Extract up to 30 distinct compilation errors with:
  - File paths
  - Line numbers and column positions (if available)
  - Error messages and error codes

â†’ Display compilation error summary to user

â†’ Use AskUserQuestion: "Build failed with [N] compilation errors. Fix them?"
  - "Yes" â†’ Proceed to step 3b
  - "No" â†’ Stop

## 3b. Delegate to Build-Fixer Agent

â†’ Use the `build-fixer` agent to fix compilation errors one-by-one.

â†’ Provide agent with context in natural language:
  - Build error list: [bulleted list with file:line:col and error messages from step 3a]
  - Example error entry: "src/auth.ts:45:12 - TS2304: Cannot find name 'User'"

â†’ Provide env variable values to agent:
  - `CLAUDE_PLUGIN_ROOT` actual path (e.g., "/Users/youruser/.claude/plugins/dev-workflow@noahlz.github.io")
  - `BUILD_CMD` actual value (e.g., "npm run build")
  - `BUILD_LOG` actual path (e.g., "dist/npm-build.log")
  - `BUILD_ERROR_PATTERN` actual pattern (e.g., "(error|Error|ERR!)")
  - `BUILD_WORKING_DIR` actual path (e.g., ".")
  - `LOG_DIR` actual path (e.g., "dist/")
  - `INITIAL_PWD` actual path (e.g., "/current/working/directory")

â†’ Agent fixes the errors per its instructions and context provided.

âœ“ Agent completes â†’ Proceed to step 3c

## 3c. Rebuild After Fixes

â†’ Return to step 3 (Build Project) to verify fixes

## 4. Run Tests

â†’ Determine test command based on mode:
  - Single test mode: TEST_CMD = `$TEST_SINGLE_CMD` with {testFile} replaced
  - All tests mode: TEST_CMD = `$TEST_CMD`

â†’ Change to test working directory (if different from build dir)  
â†’ Execute test command silently to log file: `$TEST_CMD > "$TEST_LOG" 2>&1`  
âœ“ Exit 0 â†’ Return to INITIAL_PWD, all tests pass, proceed to step 8 (Completion)  
âœ— Exit non-zero â†’ Return to INITIAL_PWD, tests failed, proceed to step 5 (Extract Test Errors)  

## 5. Extract Test Errors

â†’ Parse test log at `$TEST_LOG` to identify failing tests  
â†’ Extract error patterns from log using `$TEST_ERROR_PATTERN` regex  
â†’ Identify failing tests (up to 30 distinct failures)  

âœ“ 0 failures detected â†’ Proceed to step 8 (Completion)  
âœ— 1-30 failures â†’ Display error summary, proceed to step 6  
âœ— 30+ failures â†’ Display count, proceed to step 6  

â†’ Display error summary to user with:
  - List of failing test names/paths
  - Error messages and relevant output from test log
  - Stack traces (if available)

## 6. Ask to Fix Tests

â†’ Check failure count from step 5:

**If 30+ failures:**  
âš ï¸ Display: "30+ tests failed. This is too many for efficient fixing in one chat."  
â†’ Use AskUserQuestion:  
  - "Attempt to fix 30+ tests?" (not recommended)  
  - "No, I'll stop and create a plan"  
â†’ If "No" â†’ Stop (user exits to create plan)  
â†’ If "Yes" â†’ Continue to step 7  

**If 1-29 failures:**  
â†’ Use AskUserQuestion:  
  - "Start fixing tests?" (recommended)
  - "No, I'll fix manually"
â†’ If "Yes" â†’ Continue to step 7  
â†’ If "No" â†’ Stop  

## 7. Delegate to Test-Fixer Agent

â†’ Use the `test-fixer` agent to fix failing tests one-by-one.

â†’ Store agent ID for potential resumption: `TEST_FIXER_AGENT_ID=[agent_id]`

â†’ Provide agent with context in natural language:
  - Failed test list: [bulleted list with test names and error excerpts from step 5]
  - Example failed test entry: "TestLoginFlow (test/auth.test.js) - Expected 'logged in', got undefined"

â†’ Provide env variable values to agent:
  - `CLAUDE_PLUGIN_ROOT` actual path
  - `TEST_SINGLE_CMD` actual value (e.g., "npm test --testNamePattern={testName}")
  - `TEST_SINGLE_LOG` actual path (e.g., "logs/test-single.log")
  - `BUILD_CMD` actual value (for compilation checking)
  - `BUILD_LOG` actual path (for compilation checking)
  - `BUILD_WORKING_DIR` actual path (for compilation checking)
  - `LOG_DIR` actual path (e.g., "logs/")
  - `INITIAL_PWD` actual path (e.g., "/current/working/directory")

â†’ Agent fixes the tests per its instructions and context provided.

âœ“ Agent completes without delegation â†’ Proceed to step 7d  
ðŸ”„ Agent exits with COMPILATION_ERROR delegation â†’ Proceed to step 7b  

## 7b. Handle Compilation Error Delegation

â†’ Detect delegation signal in test-fixer's final message:
  - Look for: "ðŸ”„ DELEGATION_REQUIRED: COMPILATION_ERROR"

â†’ Extract build errors from BUILD_LOG (similar to step 3a)

â†’ Use AskUserQuestion:
  - "Test fix introduced compilation errors. Fix them with build-fixer?"
  - "Yes" â†’ Continue to step 7c
  - "No" â†’ Proceed to step 7d

## 7c. Invoke Build-Fixer and Resume Test-Fixer

â†’ Invoke build-fixer agent with compilation errors and env variables:
  - `CLAUDE_PLUGIN_ROOT` actual path
  - `BUILD_CMD` actual value
  - `BUILD_LOG` actual path
  - `BUILD_ERROR_PATTERN` actual pattern
  - `BUILD_WORKING_DIR` actual path
  - `LOG_DIR` actual path
  - `INITIAL_PWD` actual path

â†’ After build-fixer completes: Rebuild to verify
  - `cd $BUILD_WORKING_DIR && $BUILD_CMD > $BUILD_LOG 2>&1`
  - If build fails: Return to step 7b (more compilation errors)
  - If build succeeds: Continue to resume test-fixer

â†’ Resume test-fixer agent using Task tool with resume parameter:
  - resume: $TEST_FIXER_AGENT_ID
  - prompt: "Compilation errors have been resolved by build-fixer. BUILD_LOG shows clean build. Continue with test fix verification."

â†’ Test-fixer continues from where it left off (re-runs verification)

âœ“ Test-fixer completes â†’ Proceed to step 7d  
ðŸ”„ Test-fixer delegates again â†’ Loop back to step 7b (compilation errors reintroduced)  

## 7d. Ask User to Re-run Tests

â†’ Use AskUserQuestion:
  - "Re-run all tests to verify fixes?"
  - "No, stop for now"

âœ“ User confirms â†’ Proceed to step 4 (Run Tests)  
âœ— User declines â†’ Proceed to step 8  

## 8. Completion

â†’ Check if all originally-failing tests were fixed:
  - If yes â†’ Display: "âœ… All tests fixed and passed!"
  - If no â†’ Display: "âš ï¸ Workflow incomplete. Some tests remain unfixed."

â†’ Show summary:
  - Tests fixed in this session
  - Tests skipped/remaining
  - Root causes addressed

â†’ Clear todo list with TodoWrite (empty)  
â†’ Exit  

---

**âš ï¸  CRITICAL EXECUTION RULES**

- **Silent execution**: NEVER use `tee` when running build or test commands. Redirect all output to log files (`> "$LOG_FILE" 2>&1`). Only inspect logs when command returns non-zero exit code.
- **Exit code checking**: Always capture and check exit codes to resolve build and test success/failure. Zero = success, non-zero = failure.
- **No assumptions**: Never assume errors are "pre-existing" or skip investigating them. All errors must be analyzed unless user explicitly stops the workflow.
- **No Git Commits:** DO NOT commit changes as part of this workflow. Users will do that separately.
