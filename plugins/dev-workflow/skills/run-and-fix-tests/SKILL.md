---
name: run-and-fix-tests
description: Build the project, run tests and systematically fix any failures. Activate when user says phrases such as "run tests", "test", "build and test" or "fix tests".
---

## 0. Resolve Plugin Root

â†’ Resolve plugin root environment (check local project first, then user home):
```bash
RESOLVER=""
if [ -x "./.claude/resolve_plugin_root.sh" ]; then
  RESOLVER="./.claude/resolve_plugin_root.sh"
elif [ -x "$HOME/.claude/resolve_plugin_root.sh" ]; then
  RESOLVER="$HOME/.claude/resolve_plugin_root.sh"
else
  echo "Error: resolve_plugin_root.sh not found in ./.claude/ or $HOME/.claude/" >&2
  exit 1
fi
CLAUDE_PLUGIN_ROOT="$($RESOLVER "dev-workflow@noahlz.github.io")" || { echo "Error: Failed to resolve plugin root" >&2; exit 1; }
export CLAUDE_PLUGIN_ROOT
```

âœ“ Plugin root resolved â†’ Proceed to step 1 (Detect Build Configuration)

## 1. Detect Build Configuration

â†’ Check if `.claude/settings.plugins.run-and-fix-tests.json` exists  
âœ“ Config exists â†’ Proceed to step 2  
âœ— Config missing â†’ Run detection and auto-config:  

â†’ Execute: `node ${CLAUDE_PLUGIN_ROOT}/skills/run-and-fix-tests/scripts/detect-and-resolve.js "${CLAUDE_PLUGIN_ROOT}"`
  - Scans project for build tool config files (package.json, pom.xml, build.gradle, etc.)
  - Detects which tools are present
  - Outputs JSON array of detected tools with configurations

â†’ Auto-selection rules:
  - Exactly 1 tool detected â†’ Use `defaults/{tool}.json`
  - Multiple tools in different locations â†’ Generate polyglot config (ðŸ”§ shown to user)
  - Multiple tools in same location â†’ Generate polyglot config
  - No matching default exists â†’ Use `TEMPLATE.json` placeholder template (user must customize)
  - 0 tools detected â†’ Error: no build tools detected

âœ“ Config created successfully â†’ Proceed to step 2  
âœ— No tools detected â†’ Error, user must create `.claude/settings.plugins.run-and-fix-tests.json` manually  
âœ— Using placeholder config â†’ User must edit `.claude/settings.plugins.run-and-fix-tests.json` before step 2  

## 2. Load Configuration

â†’ Execute load-config script to output configuration as eval-able statements:
```bash
eval "$(node ${CLAUDE_PLUGIN_ROOT}/skills/run-and-fix-tests/scripts/load-config.js "${CLAUDE_PLUGIN_ROOT}")"
```
âœ— Script fails â†’ Display error and stop  
âœ“ Script succeeds â†’ Environment variables set:
  - BUILD_CMD, BUILD_LOG, BUILD_ERROR_PATTERN, BUILD_WORKING_DIR
  - TEST_CMD, TEST_LOG, TEST_ERROR_PATTERN
  - TEST_SINGLE_CMD, TEST_SINGLE_LOG, TEST_SINGLE_ERROR_PATTERN
  - LOG_DIR (tool-specific, e.g., dist/, build/, target/)
  - BUILD_MULTI (true if multi-build, false if single)

â†’ Check command argument: `TEST_FILE="$1"`  
â†’ Determine mode:
  - `$TEST_FILE` not empty â†’ Single test mode
  - `$TEST_FILE` empty â†’ All tests mode

â†’ Store initial working directory: `INITIAL_PWD=$(pwd)`

## Common Definitions

### BUILD_FIXER_ENV_VARS

Environment variables to provide when delegating to build-fixer agent:
- `CLAUDE_PLUGIN_ROOT` - actual path (e.g., "/Users/user/.claude/plugins/dev-workflow@noahlz.github.io")
- `BUILD_CMD` - actual value (e.g., "npm run build")
- `BUILD_LOG` - actual path (e.g., "dist/npm-build.log")
- `BUILD_ERROR_PATTERN` - actual pattern (e.g., "(error|Error|ERR!)")
- `BUILD_WORKING_DIR` - actual path (e.g., ".")
- `LOG_DIR` - actual path (e.g., "dist/")
- `INITIAL_PWD` - actual path (e.g., "/current/working/directory")

### TEST_FIXER_ENV_VARS

Environment variables to provide when delegating to test-fixer agent:
- BUILD_FIXER_ENV_VARS (see above) for compilation checking
- `TEST_SINGLE_CMD` - actual value (e.g., "npm test --testNamePattern={testName}")
- `TEST_SINGLE_LOG` - actual path (e.g., "logs/test-single.log")

### EXTRACT_BUILD_ERRORS

Procedure to extract compilation errors from build log:

â†’ Try to get language diagnostics from editor using available IDE MCP or LSP tools  
âœ“ MCP or LSP tool available â†’ Extract errors with precise locations  
âœ— Not available â†’ Parse build log at `$BUILD_LOG` using `$BUILD_ERROR_PATTERN` regex  

â†’ Extract up to 30 distinct compilation errors with:
  - File paths
  - Line numbers and column positions (if available)
  - Error messages and error codes

â†’ Display compilation error summary to user

### DELEGATE_TO_BUILD_FIXER

Procedure to delegate to build-fixer agent:

â†’ Use the `build-fixer` agent to fix compilation errors one-by-one.

â†’ Provide agent with context in natural language:
  - Build error list: [bulleted list with file:line:col and error messages]
  - Example error entry: "src/auth.ts:45:12 - TS2304: Cannot find name 'User'"

â†’ Provide BUILD_FIXER_ENV_VARS (see above)

â†’ Agent fixes the errors per its instructions and context provided.

### REBUILD_AND_VERIFY

Procedure to rebuild project and verify compilation:

â†’ Change to build working directory and rebuild:
  `cd $BUILD_WORKING_DIR && $BUILD_CMD > $BUILD_LOG 2>&1 && cd $INITIAL_PWD`

â†’ Check exit code:
  - Exit 0 â†’ Build succeeded
  - Exit non-zero â†’ Build failed, check BUILD_LOG for errors

### RESUME_TEST_FIXER

Procedure to resume test-fixer agent after build-fixer completes:

â†’ Resume test-fixer agent using Task tool with resume parameter:
  - `resume: $TEST_FIXER_AGENT_ID`
  - `prompt: "Compilation errors have been resolved by build-fixer. BUILD_LOG shows clean build. Continue with test fix verification."`

â†’ Test-fixer continues from where it left off (re-runs verification starting with compilation check)

## 3. Build Project

â†’ Create log directory: `mkdir -p "$LOG_DIR"`
â†’ Check build type: `$BUILD_MULTI`

**Single Build (BUILD_MULTI=false):**
â†’ Change to build working directory: `cd "$BUILD_WORKING_DIR"`
â†’ Execute build command silently to log file: `$BUILD_CMD > "$BUILD_LOG" 2>&1`
âœ“ Exit 0 â†’ Return to INITIAL_PWD, proceed to step 4 (Run Tests)
âœ— Exit non-zero â†’ Return to INITIAL_PWD, proceed to step 3a (Extract Build Errors)

**Multi-Build (BUILD_MULTI=true):**
â†’ Iterate through BUILD_COUNT (number of builds):
  â†’ For each index i from 0 to (BUILD_COUNT - 1):
    - Extract variables: BUILD_${i}_CMD, BUILD_${i}_LOG, BUILD_${i}_WORKING_DIR, BUILD_${i}_ERROR_PATTERN
    - Change to: `cd "${BUILD_${i}_WORKING_DIR}"`
    - Execute: `${BUILD_${i}_CMD} > "${BUILD_${i}_LOG}" 2>&1`
    - On exit 0: continue to next build
    - On exit non-zero: return to INITIAL_PWD, proceed to step 3a with ALL failed builds collected

â†’ When extracting errors from multiple failed builds:
  - Parse each failed build's log file
  - Prefix errors with tool name/location for clarity
  - Aggregate into single error list for step 3a

âœ“ All builds succeed â†’ Return to INITIAL_PWD, proceed to step 4 (Run Tests)

## 3a. Extract Build Errors

â†’ Extract errors (see EXTRACT_BUILD_ERRORS)

â†’ Use AskUserQuestion: "Build failed with [N] compilation errors. Fix them?"
  - "Yes" â†’ Proceed to step 3b
  - "No" â†’ Stop

## 3b. Delegate to Build-Fixer Agent

â†’ Delegate to build-fixer with error list from step 3a (see DELEGATE_TO_BUILD_FIXER)

âœ“ Agent completes â†’ Proceed to step 3c

## 3c. Rebuild After Fixes

â†’ Return to step 3 (Build Project) to verify fixes

## 4. Run Tests

â†’ Determine test command based on mode:
  - Single test mode: TEST_CMD = `$TEST_SINGLE_CMD` with {testFile} replaced
  - All tests mode: TEST_CMD = `$TEST_CMD`

â†’ Change to test working directory (if different from build dir)  
â†’ Execute test command silently to log file: `$TEST_CMD > "$TEST_LOG" 2>&1`  
âœ“ Exit 0 â†’ Return to INITIAL_PWD, all tests pass, proceed to step 8 (Completion)  
âœ— Exit non-zero â†’ Return to INITIAL_PWD, tests failed, proceed to step 5 (Extract Test Errors)  

## 5. Extract Test Errors

â†’ Parse test log at `$TEST_LOG` to identify failing tests  
â†’ Extract error patterns from log using `$TEST_ERROR_PATTERN` regex  
â†’ Identify failing tests (up to 30 distinct failures)  

âœ“ 0 failures detected â†’ Proceed to step 8 (Completion)  
âœ— 1-30 failures â†’ Display error summary, proceed to step 6  
âœ— 30+ failures â†’ Display count, proceed to step 6  

â†’ Display error summary to user with:
  - List of failing test names/paths
  - Error messages and relevant output from test log
  - Stack traces (if available)

## 6. Ask to Fix Tests

â†’ Check failure count from step 5:

**If 30+ failures:**  
âš ï¸ Display: "30+ tests failed. This is too many for efficient fixing in one chat."  
â†’ Use AskUserQuestion:  
  - "Attempt to fix 30+ tests?" (not recommended)  
  - "No, I'll stop and create a plan"  
â†’ If "No" â†’ Stop (user exits to create plan)  
â†’ If "Yes" â†’ Continue to step 7  

**If 1-29 failures:**  
â†’ Use AskUserQuestion:  
  - "Start fixing tests?" (recommended)
  - "No, I'll fix manually"
â†’ If "Yes" â†’ Continue to step 7  
â†’ If "No" â†’ Stop  

## 7. Delegate to Test-Fixer Agent

â†’ Use the `test-fixer` agent to fix failing tests one-by-one

â†’ Store agent ID for potential resumption: `TEST_FIXER_AGENT_ID=[agent_id]`

â†’ Provide agent with context in natural language:
  - Failed test list: [bulleted list with test names and error excerpts from step 5]
  - Example failed test entry: "TestLoginFlow (test/auth.test.js) - Expected 'logged in', got undefined"

â†’ Provide TEST_FIXER_ENV_VARS (see Common Definitions)

â†’ Agent fixes the tests per its instructions and context provided

âœ“ Agent completes without delegation â†’ Proceed to step 7d  
ðŸ”„ Agent exits with COMPILATION_ERROR delegation â†’ Proceed to step 7b  

## 7b. Handle Compilation Error Delegation

â†’ Detect delegation signal in test-fixer's final message:  
Look for: "ðŸ”„ DELEGATION_REQUIRED: COMPILATION_ERROR"

â†’ Extract build errors (see EXTRACT_BUILD_ERRORS)

â†’ Use AskUserQuestion:
  - "Test fix introduced compilation errors. Fix them with build-fixer?"
  - "Yes" â†’ Continue to step 7c
  - "No" â†’ Proceed to step 7d

## 7c. Invoke Build-Fixer and Resume Test-Fixer

â†’ Delegate to build-fixer with error list from step 7b (see DELEGATE_TO_BUILD_FIXER)

â†’ After build-fixer completes: Rebuild to verify (see REBUILD_AND_VERIFY)
  - If build fails: Return to step 7b (more compilation errors)
  - If build succeeds: Continue to resume test-fixer

â†’ Resume test-fixer (see RESUME_TEST_FIXER)

âœ“ Test-fixer completes â†’ Proceed to step 7d
ðŸ”„ Test-fixer delegates again â†’ Loop back to step 7b (compilation errors reintroduced)  

## 7d. Ask User to Re-run Tests

â†’ Use AskUserQuestion:
  - "Re-run all tests to verify fixes?"
  - "No, stop for now"

âœ“ User confirms â†’ Proceed to step 4 (Run Tests)  
âœ— User declines â†’ Proceed to step 8  

## 8. Completion

â†’ Check if all originally-failing tests were fixed:
  - If yes â†’ Display: "âœ… All tests fixed and passed!"
  - If no â†’ Display: "âš ï¸ Workflow incomplete. Some tests remain unfixed."

â†’ Show summary:
  - Tests fixed in this session
  - Tests skipped/remaining
  - Root causes addressed

â†’ Clear todo list with TodoWrite (empty)  
â†’ Exit  

---

**âš ï¸  CRITICAL EXECUTION RULES**

- **Silent execution**: NEVER use `tee` when running build or test commands. Redirect all output to log files (`> "$LOG_FILE" 2>&1`). Only inspect logs when command returns non-zero exit code.
- **Exit code checking**: Always capture and check exit codes to resolve build and test success/failure. Zero = success, non-zero = failure.
- **No assumptions**: Never assume errors are "pre-existing" or skip investigating them. All errors must be analyzed unless user explicitly stops the workflow.
- **No Git Commits:** DO NOT commit changes as part of this workflow. Users will do that separately.
