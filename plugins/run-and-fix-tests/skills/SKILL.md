---
name: run-and-fix-tests
description: Build project and run tests with clean output, fix any failures. Activate when user says "run tests", "test", "build and test", "fix tests", or "make test".
---

## 0. Detect Build Configuration

â†’ Check if `.claude/build-config.json` exists and is not empty
âœ“ Config exists â†’ Proceed to step 1
âœ— Config missing/empty â†’ Run detection script:

â†’ Source: `${CLAUDE_PLUGIN_ROOT}/scripts/detect-and-resolve.sh`
  - Scans project for build tool config files (package.json, pom.xml, build.gradle, etc.)
  - Loads merged config (default + project override)
  - Returns: `$DETECTED_TOOLS` (JSON array), `$BUILD_CONFIG` (merged config)

â†’ Check number of detected tools:
  - Exactly 1 tool â†’ Propose single build configuration
  - Multiple tools â†’ Proceed to step 0a
  - 0 tools â†’ Error: no build tools detected

## 0a. Resolve Ambiguity (if multiple tools at same location)

â†’ Check if all detected tools are in same directory (e.g., all in project root)
âœ“ All in different directories â†’ Proceed to multi-build proposal
âœ— Multiple tools in same directory â†’ Ask user to choose:

â†’ Use AskUserQuestion:
  - Question: "Multiple build tools detected in [location]. Which should I use?"
  - Options: List detected tools as choices
  - Recommended: First detected tool

âœ“ User selects tool â†’ Create single-build config with selected tool, proceed to step 1
âœ— User chooses "Other/Configure manually" â†’ Stop

## 0b. Propose Configuration

â†’ Display detected tools and their locations:
  - Single tool: "Detected [tool] at [location]"
  - Multiple tools: "Detected [tool1] at [location1], [tool2] at [location2], etc."

â†’ Use AskUserQuestion to confirm:
  - "Proceed with these build tools?" (recommended)
  - "No, I'll configure manually"
  - "Other"

âœ“ User confirms â†’ Save config to `.claude/build-config.json` and proceed to step 1
âœ— User declines â†’ Stop, user creates `.claude/build-config.json` manually

## 1. Load Configuration

â†’ Source: `${CLAUDE_PLUGIN_ROOT}/scripts/load-config.sh`
âœ— Script fails â†’ Display error and stop
âœ“ Script succeeds â†’ Environment variables set:
  - BUILD_CMD, BUILD_LOG, BUILD_ERROR_PATTERN, BUILD_WORKING_DIR
  - TEST_CMD, TEST_LOG, TEST_ERROR_PATTERN
  - TEST_SINGLE_CMD, TEST_SINGLE_LOG, TEST_SINGLE_ERROR_PATTERN
  - LOG_DIR (tool-specific, e.g., dist/, build/, target/)
  - BUILD_MULTI (true if multi-build, false if single)

â†’ Check command argument: `TEST_FILE="$1"`
â†’ Determine mode:
  - `$TEST_FILE` not empty â†’ Single test mode
  - `$TEST_FILE` empty â†’ All tests mode

â†’ Store initial working directory: `INITIAL_PWD=$(pwd)`

## 2. Build Project

â†’ Create log directory: `mkdir -p "$LOG_DIR"`
â†’ Check build type: `$BUILD_MULTI`

**Single Build:**
â†’ Change to build working directory: `cd "$BUILD_WORKING_DIR"`
â†’ Execute build command (using BUILD_CMD, BUILD_LOG, BUILD_ERROR_PATTERN)
âœ“ Exit 0 â†’ Return to INITIAL_PWD, proceed to step 3
âœ— Exit non-zero â†’ Extract errors from log
  â†’ Return to INITIAL_PWD
  â†’ Ask user: "Build failed. Should I fix it?"
    - "Yes" â†’ Analyze and fix issues, return to step 2
    - "No" â†’ Stop

**Multi-Build:**
â†’ For each build in detected tools:
  â†’ Change to build working directory
  â†’ Execute build command
  â†’ On failure: extract errors, return to INITIAL_PWD, ask user to fix
  â†’ On success: continue to next build

âœ“ All builds succeed â†’ Return to INITIAL_PWD, proceed to step 3
âœ— Any build fails â†’ Return to INITIAL_PWD, ask user: "Build failed in [tool]. Should I fix it?"
  - "Yes" â†’ Analyze and fix, return to step 2
  - "No" â†’ Stop

## 3. Run Tests

â†’ Determine test command based on mode:
  - Single test mode: TEST_CMD = `$TEST_SINGLE_CMD` with {testFile} replaced
  - All tests mode: TEST_CMD = `$TEST_CMD`

â†’ Change to test working directory (if different from build dir)
â†’ Execute test command (log to $TEST_LOG)
âœ“ Exit 0 â†’ Return to INITIAL_PWD, all tests pass, proceed to step 6
âœ— Exit non-zero â†’ Return to INITIAL_PWD, tests failed, proceed to step 4

## 4. Extract Errors

â†’ Parse test log to identify failing tests
â†’ Extract error patterns from log (up to 30 errors)
â†’ Display error summary to user

## 5. Create Fix Plan

â†’ Analyze failures to identify distinct failing tests
â†’ Use TodoWrite to create todo list (one per failing test)
â†’ Status: "pending"

## 6. Ask to Fix Tests

â†’ Use AskUserQuestion:
  - "Start fixing tests one by one?" (recommended)
  - "No, I'll fix manually"
  - "Other"

âœ“ "Yes" â†’ Proceed to step 7
âœ— "No" â†’ Stop

## 7. Fix Tests Iteratively

â†’ Get next pending test from todo list
â†’ Mark as "in_progress"
â†’ Fix the test (modify relevant code)
â†’ Mark as "completed"
â†’ Use AskUserQuestion:
  - "Fix next test?" (if more remain)
  - "Re-run all tests?"
  - "Stop for now"
  - "Other"

âœ“ "Fix next test" â†’ If tests remain, return to step 7; else run step 3
âœ“ "Re-run all tests" â†’ Clear todos, return to step 3
âœ— "Stop for now" â†’ Stop

## 8. Success

âœ… All tests passed
â†’ Clear todo list with TodoWrite (empty)
â†’ Display success message with log file locations

ğŸ”§ Configuration: `.claude/build-config.json` (optional project override)
ğŸ“ Logs directory: `$LOG_DIR` (tool-specific: dist/ for npm, target/ for maven, build/ for gradle, etc.)